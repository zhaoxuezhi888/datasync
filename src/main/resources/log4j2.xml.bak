<?xml version="1.0" encoding="UTF-8"?>
<!--Configuration后面的status,这个用于设置log4j2自身内部的信息输出,可以不设置,当设置成trace时,你会看到log4j2内部各种详细输出-->
<!--monitorInterval:定时检测配置文件的修改,有变化则自动重新加载配置,时间单位为秒,最小间隔为30s -->
<!--主日志文件${FLINK_LOG_DIR}/flink-${FLINK_IDENT_STRING}-${DAEMON}-${id}-${HOSTNAME}-->
<!--对应的环境变量为log.flink_dir,log.flink_ident,log.flink_daemon,log.flink_id,log.flink_hostname-->
<Configuration status="warn" monitorInterval="60">
    <!--properties:设置全局变量 -->
    <properties>
        <Property name="level">INFO</Property>
        <!--LOG_HOME:指定当前日志存放的目录 -->
        <property name="LOG_HOME">/data/logs</property>
        <!--FILE_NAME:指定日志文件的名称 -->
        <property name="FILE_INFO_NAME">
            info
        </property>
        <property name="FILE_ERROR_NAME">
            error
        </property>
        <property name="FILE_TRACE_NAME">
            trace
        </property>
        <Property name="LOG_PATTERN">
            %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x %X{traceid} - %m%n
        </Property>
        <!--LOG_HOME:指定当前日志存放的目录 -->
        <!--<property name="LOG_HOME">${sys:log.flink_dir}</property>
        &lt;!&ndash;FILE_NAME:指定日志文件的名称 &ndash;&gt;
        <property name="FILE_INFO_NAME">
            flink-${sys:log.flink_ident}-${sys:log.flink_daemon}-${sys:log.flink_id}-${sys:log.flink_hostname}
        </property>
        <property name="FILE_ERROR_NAME">
            flink-${sys:log.flink_ident}-${sys:log.flink_daemon}-${sys:log.flink_id}-${sys:log.flink_hostname}-error
        </property>-->
    </properties>

    <!--Appenders:定义日志输出目的地，内容和格式等 -->
    <Appenders>
        <!--Console:日志输出到控制台标准输出
        Console节点用来定义输出到控制台的Appender.name:指定Appender的名字.target:SYSTEM_OUT 或 SYSTEM_ERR,一般只设置默认:SYSTEM_OUT.
        PatternLayout:输出格式，不设置默认为:%m%n.
         -->
        <Console name="ConsoleAppender" target="SYSTEM_OUT">
            <!--pattern:日期,线程名,日志级别,日志名称,日志信息,换行 -->
            <!-- 日志文件默认输出格式,另类带行号输出(对日志输出性能未知);%C:大写,类名;%M:方法名;%L:行号;%m:错误信息;%n:换行 -->
            <PatternLayout pattern="${LOG_PATTERN}"/>
            <ThresholdFilter level="TRACE" onMatch="ACCEPT" onMismatch="DENY"/>
        </Console>

        <RollingRandomAccessFile name="MainAppender" fileName="${LOG_HOME}/${FILE_INFO_NAME}.log"
                                 filePattern="${LOG_HOME}/$${date:yyyy-MM}/${FILE_INFO_NAME}-%d{yyyy-MM-dd}-%i.log.zip">
            <PatternLayout pattern="${LOG_PATTERN}"/>
            <Filters>
                <!--如果日志事件LogEvent中有kafka_marker标记，则直接拒绝这个日志事件-->
                <MarkerFilter marker="kafka_marker" onMatch="DENY" onMismatch="NEUTRAL"/>
                <!--如果日志事件LogEvent中的日志等级为${level}及以上，则接受这个日志事件-->
                <ThresholdFilter level="${level}" onMatch="ACCEPT" onMismatch="DENY"/>
            </Filters>
            <!--Policies:触发策略决定何时执行备份 -->
            <Policies>
                <!--程序启动时候执行一次rollover-->
                <OnStartupTriggeringPolicy/>
                <!--TimeBasedTriggeringPolicy:日志文件按照时间备份 -->
                <!--interval:每1天生成一个新文件，时间单位需要结合filePattern时间%d{yyyy-MM-dd} -->
                <!--同理，如果要每X小时生成一个新文件，则改成%d{yyyy-MM-dd-HH} -->
                <!--modulate:对备份日志的生成时间纠偏，纠偏以0为基准进行，"0+interval"决定启动后第一次备份时间 -->
                <TimeBasedTriggeringPolicy interval="1" modulate="true"/>
                <!--SizeBasedTriggeringPolicy:日志文件按照大小备份 -->
                <!--size:指定日志文件最大为300MB，单位可以为KB、MB或GB -->
                <SizeBasedTriggeringPolicy size="300MB"/>
            </Policies>
            <!--DefaultRolloverStrategy:翻转策略决定如何执行备份 -->
            <!--max:最多保存5个备份文件，结合时间使用后，在每个时间段内最多有5个备份，多出来的会被覆盖 -->
            <!--compressionLevel:配置日志压缩级别，范围0-9，0不压缩，1压缩速度最快，9压缩率最好，目前只对于zip压缩文件类型有效 -->
            <DefaultRolloverStrategy max="30">
                <!--Delete:删除匹配到的过期备份文件 -->
                <!--maxDepth:由于备份文件保存在${LOG_HOME}/$${date:yyyy-MM-dd},所以目录深度设置为2 -->
                <Delete basePath="${LOG_HOME}/$${date:yyyy-MM}" maxDepth="2">
                    <!--IfFileName:匹配文件名称 -->
                    <!--glob:匹配2级目录深度下的以.log结尾的备份文件 -->
                    <IfFileName glob="*/*.log.zip"/>
                    <!--IfLastModified:匹配文件修改时间 -->
                    <!--age:匹配超过180小时的文件，单位D、H、M、S分别表示天、小时、分钟、秒-->
                    <IfLastModified age="72H"/>
                </Delete>
            </DefaultRolloverStrategy>
        </RollingRandomAccessFile>

        <!--输入错误级别日志-->
        <RollingRandomAccessFile name="ErrorAppender" fileName="${LOG_HOME}/${FILE_ERROR_NAME}.log"
                                 filePattern="${LOG_HOME}/$${date:yyyy-MM}/${FILE_ERROR_NAME}-%d{yyyy-MM-dd}-%i.log.zip">
            <PatternLayout pattern="${LOG_PATTERN}"/>
            <Filters>
                <MarkerFilter marker="error_marker" onMatch="ACCEPT" onMismatch="DENY"/>
            </Filters>
            <Policies>
                <OnStartupTriggeringPolicy/>
                <TimeBasedTriggeringPolicy interval="1" modulate="true"/>
                <SizeBasedTriggeringPolicy size="300MB"/>
            </Policies>
            <DefaultRolloverStrategy max="30">
                <Delete basePath="${LOG_HOME}/$${date:yyyy-MM}" maxDepth="2">
                    <IfFileName glob="*/*.log.zip"/>
                    <IfLastModified age="72H"/>
                </Delete>
            </DefaultRolloverStrategy>
        </RollingRandomAccessFile>

        <!--消息跟踪日志-->
        <RollingRandomAccessFile name="TraceAppender" fileName="${LOG_HOME}/${FILE_TRACE_NAME}.log"
                                 filePattern="${LOG_HOME}/$${date:yyyy-MM}/${FILE_TRACE_NAME}-%d{yyyy-MM-dd}-%i.log.zip">
            <!--JSONLayout：作为"Console" Appender的布局模式，用于将日志事件输出为JSON格式,complete="true"：表示输出完整的JSON文档
            compact="false"：表示输出易读性的格式的JSON。 eventEol="false"：表示不在每个日志事件之后添加换行符。
            properties="true"：表示将日志事件的属性输出为JSON对象的属性。
            <KeyValuePair key="ecs.version" value="1.11.0" />：添加了一个自定义的属性，指定使用的ECS版本。
            -->
            <JsonTemplateLayout charset="utf-8" stackTraceEnabled="false">

            </JsonTemplateLayout>
            <Filters>
                <MarkerFilter marker="trace_marker" onMatch="ACCEPT" onMismatch="DENY"/>
            </Filters>
            <Policies>
                <OnStartupTriggeringPolicy/>
                <TimeBasedTriggeringPolicy interval="1" modulate="true"/>
                <SizeBasedTriggeringPolicy size="300MB"/>
            </Policies>
            <DefaultRolloverStrategy max="30">
                <Delete basePath="${LOG_HOME}/$${date:yyyy-MM}" maxDepth="2">
                    <IfFileName glob="*/*.log.zip"/>
                    <IfLastModified age="72H"/>
                </Delete>
            </DefaultRolloverStrategy>
        </RollingRandomAccessFile>

        <!--发送日志到kafka intellis_push_hj91neao_dc_busilog-->
        <!--<Kafka name="KafkaAppender" topic="yondif_datasync_log" syncSend="false">
            <Filters>
                <MarkerFilter marker="kafka_marker" onMatch="ACCEPT" onMismatch="DENY"/>
            </Filters>
            <JsonTemplateLayout eventTemplateUri="classpath:YondifEcsLayout.json" charset="utf-8"
                                stackTraceEnabled="true">
                <EventTemplateAdditionalField key="marker" format="JSON"
                                              value='{"$resolver": "marker", "field": "name"}'/>
            </JsonTemplateLayout>
            <Property name="bootstrap.servers">10.16.26.85:34998</Property>
        </Kafka>-->
        <!-- 异步Appender 创建了一个名为async的AsyncAppender，并将ESJsonLayout配置在其中。通过配置bufferSize和includeLocation等属性异步输出可以一定程度上减轻程序运行时的日志压力，但仍然需要根据实际情况进行配置和优化。此外，还可以考虑日志级别的控制和日志滚动策略等，以进一步减轻日志对程序性能的影响-->
        <Async name="asyncTraceAppender" bufferSize="1024" includeLocation="false">
            <AppenderRef ref="TraceAppender"/>
        </Async>
    </Appenders>
    <!--Loggers:定义日志级别和使用的Appenders -->
    <Loggers>
        <Logger name="com.yonyougov.yondif" level="${level}" additivity="false">
            <AppenderRef ref="asyncTraceAppender"/>
            <AppenderRef ref="ErrorAppender" level="ERROR"/>
        </Logger>
        <!--Root:日志默认打印到控制台 -->
        <!--level日志级别: ALL < TRACE < DEBUG(500) < INFO(400) < WARN(300) < ERROR(200) < FATAL(100) < OFF(0) -->
        <Root level="${level}" additivity="false">
            <AppenderRef ref="ConsoleAppender"/>
            <AppenderRef ref="MainAppender"/>
        </Root>
    </Loggers>
</Configuration>
